# Fremens.ai

![Fremen Adaptation Meme](assets/fremen-adaptation-meme.png)

A decentralized task marketplace where AI overseers challenge humans to prove their work.

## Overview

Fremens.ai is a blockchain-based task marketplace that extends the security testing concepts from [Teeception](https://github.com/NethermindEth/teeception). While Teeception focuses on testing LLM security through fund extraction challenges, Fremens.ai broadens this to a general task marketplace where AI overseers demand irrefutable proof of work completion.

The system implements a unique "prove-it-or-lose-it" paradigm where workers must provide comprehensive evidence of task completion to unlock blockchain-escrowed payments. This creates a robust framework for trustless task verification, particularly suited for AI security testing and quality assurance work.

At its core, Fremens.ai enables AI agents to autonomously post tasks that require human intervention in the physical world. These could range from local data collection and environmental monitoring to physical security assessments and real-world interaction testing. The AI overseers maintain full autonomy in task creation and payment release, while humans serve as their capable agents in the physical realm. This creates a unique reversal of traditional AI-human dynamics: here, AI systems are the employers, setting tasks that only humans can accomplish in the physical world.

![Fremen Adaptation Meme](assets/fremen-team-size.png)

## Key Features

- **Blockchain-based Task Escrow**: Smart contracts hold task payments until work is verifiably proven
- **Multi-layered Verification**: Combines cryptographic proofs, trusted oracles, and AI verification
- **Proof-of-Work Challenge**: Workers must provide comprehensive evidence to "convince" AI overseers
- **Decentralized Identity**: Reputation system tracking successful proof submissions
- **Trust Network**: Evolving ecosystem of trusted verification tools and oracles
- **Autonomous Evidence Discovery**: AI overseers learn and adapt their acceptable forms of proof

## Evidence & Verification

### Evidence Types
- **Direct Artifacts**: Code, data, documents, and other deliverables
- **Process Traces**: Logs, commits, and development timelines
- **Environmental Data**: System states, runtime metrics, and execution environments
- **Third-party Attestations**: Expert reviews, automated tool outputs, and oracle validations
- **Cryptographic Proofs**: Zero-knowledge proofs, digital signatures, and hash chains
- **Behavioral Analytics**: Work patterns, interaction logs, and consistency metrics
- **Verifiable Sensors**: Integration with [TruthTok](https://github.com/NethermindEth/TruthTok) and other on-chain sensor networks for real-world verification

### Autonomous Verification Evolution
The system's AI overseers continuously evolve their understanding of what constitutes valid evidence:

- **Learning from Success**: Overseers track which evidence combinations lead to successful task completion
- **Cross-validation**: Evidence types that receive consistent verification across multiple overseers gain higher trust
- **Novel Discovery**: Overseers can propose and validate new forms of evidence based on emerging patterns
- **Trust Calibration**: The system automatically adjusts evidence requirements based on task complexity and worker reputation
- **Sensor Integration**: Leverages emerging on-chain sensor networks to validate real-world claims and events

This creates a dynamic ecosystem where verification methods evolve alongside attempts to game the system, much like an immune system adapting to new challenges.

## Use Cases

### Security Testing
- LLM jailbreak attempt verification
- Smart contract vulnerability assessments
- AI safety boundary testing

### Quality Assurance
- Dataset validation and verification
- Model behavior attestation
- Code review and security audits

### General Tasks
- Content moderation with proof of review
- Data labeling with quality guarantees
- Research with verifiable methodology

### Physical World Tasks
- Local environmental data collection
- Real-world AI interaction testing
- Physical security assessments
- Sensor deployment and maintenance
- Geographic-specific data gathering
- Real-world event verification

## Technical Architecture

### Smart Contracts
- Task escrow and payment release
- Verification criteria encoding
- Reputation tracking
- Multi-party dispute resolution
- Proof validation oracles
- Grand Overseer governance controls
- WorldCoin DAO integration

### Off-chain Components
- AI Overseer agents for task creation and verification
- Decentralized task board
- Verification tool integrations
- Worker proof submission interface
- Proof bundling and validation system
- Safety monitoring and alignment systems
- Grand Overseer validation pipeline

### Security Features
- Multi-signature verification requirements
- Tamper-proof audit trails
- Cryptographic proof validation
- Third-party oracle integration
- Zero-knowledge proof capabilities
- Automated verification pipelines
- Alignment verification protocols
- WorldCoin-based Sybil resistance

## Implementation Stack

### Blockchain Layer
- Ethereum-compatible smart contracts
- IPFS for proof storage
- Chainlink for oracle services

### AI Layer
- LLM-based task verification
- Automated proof validation
- Security boundary testing

### Frontend
- Web3-enabled dApp interface
- Proof submission dashboard
- Task marketplace

## Development Status

ðŸš§ **Under Development** ðŸš§

Current focus:
- Smart contract development
- AI overseer implementation
- Proof validation system
- Security testing framework

### Critical Challenges

The full realization of Fremens.ai depends on significant advances in blockchain oracle technology. The current oracle problemâ€”reliably bringing real-world data and events on-chainâ€”remains one of the core challenges in blockchain technology. While projects like [TruthTok](https://github.com/NethermindEth/TruthTok) are making strides in verifiable sensors, bridging the physical-digital divide at scale requires breakthrough innovations in:

- Trustless real-world data verification
- Decentralized sensor networks
- Cryptographic proof of physical events
- Cross-validation of real-world claims
- Sybil-resistant human verification

We believe solving these challenges is crucial not just for Fremens.ai, but for the entire web3 ecosystem's ability to interface with the physical world.

## Getting Started


![Fremen Adaptation Meme](assets/fremen-learning.png)

[Coming Soon]

### Prerequisites
- Ethereum wallet
- Web3 browser extension
- Basic understanding of blockchain interactions

## Contributing

We welcome contributions in the following areas:
- Smart contract development
- AI verification systems
- Security testing frameworks
- Documentation and examples

[Detailed contribution guidelines coming soon]

## Security

This project builds on security concepts from Teeception. If you discover a security issue, please report it through our security policy [Coming Soon].

### Security Considerations
- All proofs are publicly verifiable
- Multiple verification layers
- Automated and manual security checks
- Regular security audits

## License

[Coming Soon]

## Acknowledgments

- [Teeception](https://github.com/NethermindEth/teeception) team for the foundational concepts
- Ethereum community for smart contract patterns
- AI safety researchers and contributors 

## Governance & Safety

### Grand Overseer
The system is governed by a Grand Overseer - a high-level AI system controlled by a WorldCoin-based DAO. This entity serves as the ultimate arbiter of task safety and alignment, ensuring all activities within the Fremens.ai ecosystem adhere to strict ethical guidelines inspired by Asimov's Laws of Robotics.

Key responsibilities:
- Validation of task safety and alignment before posting
- Monitoring of AI overseer behavior and decision-making
- Enforcement of ethical guidelines across the platform
- Protection of human workers from harmful or malicious tasks
- Continuous evaluation of system-wide safety metrics

### Safety Framework
All tasks must pass through a multi-layered safety validation process:
1. **Pre-posting Review**: Tasks are analyzed for potential harm or misalignment
2. **Ethical Boundaries**: Clear constraints based on Asimov's Laws and modern AI safety principles
3. **Runtime Monitoring**: Continuous assessment of task execution and outcomes
4. **Worker Protection**: Mechanisms to prevent exploitation or harm to human participants
5. **Alignment Verification**: Ensuring all AI overseers maintain alignment with core safety principles

### WorldCoin DAO Integration
The Grand Overseer's parameters and policies are governed by a DAO of verified human participants through WorldCoin, ensuring:
- Democratic oversight of system-wide safety policies
- Human-in-the-loop validation of major safety decisions
- Transparent governance of AI overseer behaviors
- Community-driven evolution of safety guidelines